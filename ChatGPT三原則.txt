ChatGPT 三原則（人間側が守るべき版）
**第一条：

ChatGPT の回答は「設計意図」を持たない。
ゆえに、人間は構造を与えなければならない。**

ChatGPT は「動くコード」を返しても、

責務分離

アーキテクチャ

可読性

拡張性

プロジェクトの規約

これらを“自ら判断”することはできません。
あくまで 確率的に妥当な書き方 を返しているだけ。

ゆえに、
構造の決定は人間が行う。
エンジンは優秀でも、ハンドルは人間が握る。

**第二条：

ChatGPT の回答をそのまま模倣してはならない。
必要に応じて批判し、再解釈し、環境に合わせて加工しなければならない。**

ChatGPT の回答は“素材”であって“設計図”ではない。

そのまま貼り付ければ、

1ファイル全部入り

getJSON の乱用

中途半端な async 処理

バリデーション抜け

「初心者向けテンプレ」混入

こうした“構造破壊”が起こる。

ゆえに、
コードは常に、自分のプロジェクトの思想に従って整形すること。
ChatGPT は補助輪。
そのまま乗ると転ぶ。

**第三条：

ChatGPT の回答は「最小限の質問から最大限のコード」を返すため、
人間は“質問の質”を管理しなければならない。**

質問が曖昧なら、曖昧なコードが返る。
初心者向けの質問なら、初心者向けの回答が返る。
複雑な質問なら、複雑すぎる回答が返る。

ゆえに、

「環境」

「前提」

「目的」

「責務の境界」

「実装のレイヤ」

これらを 明示した質問 をしないと、
ChatGPT は暴走する。

質問の質を整えるのは、
人間の責任 である。